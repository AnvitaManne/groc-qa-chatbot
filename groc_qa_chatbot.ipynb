{
 "cells": [  
  {
   "cell_type": "markdown",
   "id": "a9f8d7e0-c1b2-4d3e-a8f7-b9c0d1e2a3f4",
   "metadata": {},
   "source": [
    "# Groq Chatbot with LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e2c3d4-a5f6-4g7h-i8j9-k0l1m2n3o4p5",
   "metadata": {},
   "source": [
    "## Setup and Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bb16ee-14a9-41b1-8546-81d01d9338b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install langchain langchain-groq python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09aa481-36c4-43d6-8bf1-438659e0a793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54375592-0dcd-45d2-bbab-9bc48a9542e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "if load_dotenv():\n",
    "    print(\"Environment variables loaded from .env file.\")\n",
    "else:\n",
    "    print(\"No .env file found or it's empty. \")\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "chat_model = None\n",
    "\n",
    "if not groq_api_key:\n",
    "    print(\"ERROR: GROQ_API_KEY not found in environment variables.\")\n",
    "    print(\"Please ensure it's set in your .env file.\")\n",
    "else:\n",
    "    print(\"GROQ_API_KEY loaded successfully.\")\n",
    "    try:\n",
    "        chat_model = ChatGroq(\n",
    "            groq_api_key=groq_api_key,\n",
    "            model_name=\"llama3-8b-8192\", \n",
    "            temperature=0.7 \n",
    "        )\n",
    "        print(f\"Groq Chat client initialized with model: {chat_model.model_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing Groq client: {e}\")\n",
    "        print(\"Please check your API key and model name.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d7e8f9-a0b1-4c2d-b3e4-f5g6h7i8j9k0",
   "metadata": {},
   "source": [
    "## Build LangChain Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9f150b-a711-4a3e-85fa-71f8c882a2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = None\n",
    "\n",
    "if chat_model:\n",
    "    prompt_template = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a helpful assistant. Answer the user's questions clearly and concisely.\"),\n",
    "        (\"human\", \"{question}\") \n",
    "    ])\n",
    "\n",
    "    output_parser = StrOutputParser()\n",
    "\n",
    "    # Prompt -> LLM -> Output Parser\n",
    "    qa_chain = prompt_template | chat_model | output_parser\n",
    "\n",
    "    print(\"LangChain QA chain created successfully.\")\n",
    "else:\n",
    "    print(\"Skipping LangChain pipeline creation as Groq client (chat_model) was not initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e2f3g4-h5i6-4j7k-l8m9-n0o1p2q3r4s5",
   "metadata": {},
   "source": [
    "## Test and Run Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56042c6f-15d9-4793-b450-9d03a135e158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing with sample question: 'What is the colour of the sky?'\n",
      "Bot: Thinking...\n",
      "\n",
      "LLM Response:\n",
      "The color of the sky appears to be blue to our eyes, but it can actually appear differently depending on the time of day, atmospheric conditions, and location. During the daytime, when the sun is overhead, the sky typically appears a bright blue due to the scattering of sunlight by the Earth's atmosphere. As the sun sets or rises, the sky can take on hues of red, orange, and pink due to the scattering of shorter wavelengths of light. At night, the sky can appear dark or gray, depending on the presence of moonlight or artificial light sources.\n"
     ]
    }
   ],
   "source": [
    "if qa_chain:\n",
    "    sample_question = \"What is the colour of the sky?\"\n",
    "    print(f\"\\nTesting with sample question: '{sample_question}'\")\n",
    "    print(\"Bot: Thinking...\")\n",
    "    try:\n",
    "        response = qa_chain.invoke({\"question\": sample_question})\n",
    "        print(\"\\nLLM Response:\")\n",
    "        print(response)\n",
    "    except Exception as e:\n",
    "        print(f\"Error invoking QA chain: {e}\")\n",
    "else:\n",
    "    print(\"Cannot test QA chain as it was not created (chat_model or chain setup failed).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75853d8-3b5b-4038-8996-84fb2702a3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Basic Groq QA Chatbot \n",
      "The chatbot is ready. Type your question in the input box that will appear below and press Enter.\n",
      "Type 'quit' or 'exit' to end the chat.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You (type 'quit' or 'exit'):  what is the black hole, explain in kid terms \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Thinking...\n",
      "Bot: Ooh, black holes are super cool and a little bit scary!\n",
      "\n",
      "Imagine you have a super-powerful vacuum cleaner that sucks up everything that gets too close to it. That's kind of like what a black hole is.\n",
      "\n",
      "A black hole is a really dense and heavy object in space that has such strong gravity that nothing, not even light, can escape once it gets too close. That's why it looks black, because not even light can come out of it and reach our eyes.\n",
      "\n",
      "Here's a fun way to think about it: imagine you have a super-strong magnet, and you put it near some paper clips. The magnet will pull the paper clips towards it, right? Well, a black hole is kind of like a magnet, but instead of pulling paper clips, it pulls in stars, planets, and even spaceships that get too close.\n",
      "\n",
      "But don't worry, black holes are really far away from us, so we're safe. They're actually really interesting to learn about, and scientists are still trying to figure out lots of things about them!\n",
      "\n",
      "So, that's what a black hole is in simple terms! Pretty cool, right?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if 'qa_chain' in globals() and qa_chain is not None:\n",
    "    print(\"\\n Basic Groq QA Chatbot \")\n",
    "    print(\"The chatbot is ready. Type your question in the input box that will appear below and press Enter.\")\n",
    "    print(\"Type 'quit' or 'exit' to end the chat.\")\n",
    "    while True:\n",
    "        try:\n",
    "            user_input = input(\"\\nYou (type 'quit' or 'exit'): \")\n",
    "\n",
    "            if user_input.lower() in [\"quit\", \"exit\"]:\n",
    "                print(\"Bot: Exiting chatbot.\")\n",
    "                break \n",
    "            if not user_input.strip(): \n",
    "                print(\"Bot: Please type a question.\")\n",
    "                continue\n",
    "            print(\"Bot: Thinking...\")\n",
    "            bot_response = qa_chain.invoke({\"question\": user_input})\n",
    "\n",
    "            print(f\"Bot: {bot_response}\")\n",
    "\n",
    "        except EOFError:\n",
    "            print(\"\\nBot: Exiting chatbot due to EOF. Goodbye!\")\n",
    "            break\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nBot: Chatbot interrupted by user. Goodbye!\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Bot: An error occurred: {e}\")\n",
    "            print(\"Bot: Exiting chatbot due to an unexpected error.\")\n",
    "            break \n",
    "else:\n",
    "    print(\"\\nChatbot cannot run.\")\n",
    "    print(\"Please ensure 'chat_model' (Cell 4) and 'qa_chain' (Cell 5) were initialized successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
